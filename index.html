<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="Learning to Drive Anyware via Model-Based Reannotation">
    <meta name="keywords" content="navigation, robotics, foundation model, dataset, MBRA, LogoNav">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Learning to Drive Anyware via Model-Based Reannotation</title>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZYH3N96LN5"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-ZYH3N96LN5');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/slick.css">
    <link rel="stylesheet" href="./static/css/slick-theme.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/slick.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>

    <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
            <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu">
            <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
                <div class="navbar-item has-dropdown is-hoverable">
                    <a class="navbar-link">
                        More Research
                    </a>
                    <div class="navbar-dropdown">
                        <a class="navbar-item" href="https://svl.stanford.edu/projects/dvmpc/">
                            DVMPC: Deep Visual MPC-Policy Learning for Navigation
                        </a>
                        <a class="navbar-item" href="https://sites.google.com/view/exaug-nav">
                            ExAug: Robot-conditioned Navigation Policies via Geometric Experience Augmentation
                        </a>                      
                        <a class="navbar-item" href="https://general-navigation-models.github.io/vint/index.html">
                            ViNT: A Foundation Model for Visual Navigation
                        </a>
                        <a class="navbar-item" href="https://sites.google.com/view/sacson-review/home">
                            SACSoN: Scalable Autonomous Control for Social Navigation
                        </a>
                        <a class="navbar-item" href="https://sites.google.com/view/selfi-rl/">
                            SELFI: Autonomous Self-improvement with Reinforcement Learning for Social Navigation
                        </a>
                        <a class="navbar-item" href="https://learning-language-navigation.github.io/">
                            LeLaN: Learning A Language-conditioned Navigation Policy from In-the-Wild Video
                        </a>                          
                        
                    </div>
                </div>
            </div>

        </div>
    </nav>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-2 publication-title">Learning to Drive Anyware via Model-Based Reannotation</h1>                        
                                       
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://sites.google.com/view/noriaki-hirose/">Noriaki Hirose</a><sup>1, 2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://engineering.berkeley.edu/popup/lydia-ignatova/">Lydia Ignatova</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a href="http://ajaysridhar.com/">Kyle Stachowicz</a><sup>1</sup>,
                            </span><br>
                            <span class="author-block">
                                <a href="">Catherine Glossop</a><sup>1</sup>,
                            </span>                            
                            <span class="author-block">
                                <a href="https://cs.berkeley.edu/~svlevine">Sergey Levine</a><sup>1</sup>
                            </span>                            
                            <span class="author-block">
                                <a href="https://cs.berkeley.edu/~shah">Dhruv Shah</a><sup>1, 3</sup>,
                            </span>
                        </div>

                        <div class="is-size-6 publication-authors">
                            <span class="author-block"> <sup>1</sup> University of California Berkeley,   <sup>2</sup> Toyota Motor North America,   <sup>3</sup> Princeton University</span>
                        </div>
                        <br>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/pdf/2410.03603.pdf"
                                        class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                    <i class="fas fa-file-pdf"></i>
                                    </span>
                                    <span>Paper</span>
                                    </a>
                                </span>                            
                                <!-- Talk Link. -->
                                <span class="link-block">
                                    <a href="https://youtu.be/-zTyhhu0NTY"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-youtube"></i>
                                        </span>
                                        <span>YouTube</span>
                                    </a>
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="https://github.com/NHirose/Learning-to-Drive-Anywhere-via-MBRA"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github-alt"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                                <!-- Dataset Link. -->
                                <span class="link-block">
                                    <a href="https://drive.google.com/file/d/1IazHcIyPGO7ENswz8_sGCIGBXF8_sZJK/view?usp=sharing"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-database"></i> </span>
                                        <span>Data</span>
                                    </a>
                                </span>

                                <!-- BibTex -->
                                <span class="link-block">
                                    <a href="./static/lelan.bib"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-quote-left"></i> </span>
                                        <span>BibTex</span>
                                    </a>
                                </span>

                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop is-centered has-text-justified is-size-5">
            <div class="hero-body">
                <video id="teaser" disableRemotePlayback autoplay muted loop playsinline fetchpriority="high"
                    poster="./static/images/web_pull.jpeg">
                    <source src="./static/videos_mbra/web_pull.mp4" type="video/mp4">
                </video>
            </div>
        </div>
    </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
            We present a system for training long-horizon end-to-end navigation policies capable of generalizing to deployment in highly diverse outdoor and indoor environments. The result is a single end-to-end policy capable of navigation on the scale of hundreds of meters, while generalizing to a broad distribution of unstructured environments.
To accomplish this, we must make use of every source of data available. While previous efforts to train general navigation policies typically rely on centralized researcher-collected datasets, such data is fundamentally high-quality but limited in scale. We thus turn to crowd-sourced data, which is readily available in large quantities but is relatively low-quality. To address this, we train a simple, short-horizon ``reannotation'' policy, optionally taking advantage of actions from the high-quality dataset, and use this to relabel the low-quality dataset with near-expert actions connecting short-horizon sequences of states.
The result is LogoNav, a state-of-the-art general navigation policy capable of navigating over long horizons in complex outdoor environments. We test LogoNav's generalization capabilities by evaluating performance in six countries around the world and find it to be a highly capable navigator.

            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <video autoplay controls muted loop playsinline width="100%">
              <source src="static/videos_mbra/overview.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Approach</h2>
          <div class="content has-text-justified has-text-centered">
            <h3 class="title is-4">Data annotation</h3>
            <p>
            We propose a novel method that leverages foundation models to label in-the-wild video data for training a language-conditioned navigation policy. 
            Following figure shows the overview of our data augmentation approach. 
            Our method is (i) scalable, as it uses abundant and readily available action-free data sources, (ii) efficient, as it leverages all captured objects in the image view during data augmentation, and (iii) generalizable, as it distils state-of-the-art large vision and language models to diverse and semantically meaningful annotations.
            </p>
            <img src="./static/images/system_overview.jpg" />            
            <h3 class="title is-4">Training dataset</h3>
            <p>
            We use a wide variety of egocentric datasets to train on, including: 1) Indoor Navigation Dataset: image observations from mobile robot trajectories in office building environments (see <a href="https://cvgl.stanford.edu/gonet/dataset/">GO Stanford2</a>, <a href="https://svl.stanford.edu/projects/dvmpc/dataset/">GO Stanford4</a> and <a href="https://sites.google.com/view/sacson-review/huron-dataset?authuser=0">HuRoN(SACSoN)</a> Dataset), 2) \bf YouTube Tour Dataset: YouTube video data of tours in indoor and outdoor environments, and 3) Human-walking Dataset: data collected from walking with a camera in an indoor home setting and outdoor city environments.
            </p>
            <h4 class="title is-5"> &#x2022; YouTube Tour Dataset</h4>     
            We curate about 100 hours of YouTube videos that include vastly diverse domains, which are significantly different from the university campus building settings seen in the Indoor Navigation Dataset.
            These videos from all over the world cover a broad spectrum of objects, scenes, and camera heights and types, contributing to more generalized model performance.      
            <center>    
            <video autoplay muted loop playsinline width="90%">
              <source src="static/videos/map_youtube.mp4" type="video/mp4">
            </video>     
            </center>                
            <h4 class="title is-5"> &#x2022; Human-walking Dataset</h4>   
            To address the limitation, which YouTube videos often have a narrow field of view (FOV), we collect a dataset of additional data by holding a wide FOV (fisheye) camera and collect a dataset by walking in inside and outside environments. 
            The Human-walking Dataset includes 15.7 hours of data across 11 cities in 3 different countries.    
            <center>                   
            <video autoplay muted loop playsinline width="90%">
              <source src="static/videos/map_human_walking.mp4" type="video/mp4">
              
            </video>  
            </center>                                    
            <h3 class="title is-4">Policy learning</h3>
            <p>
            We train the language-conditioned navigation policy after annotating the in-the-wild videos. 
            Our cost function includes three objectives for 1) target object reaching, 2) collision avoidance, and 3) velocity smoothness. 
            Please see the details on our manuscript and the released codes.
            </p>
          </div>
        </div>
      </div>

      <section class="section">
        <div class="container is-max-desktop">

          <div class="columns is-centered">


            <!-- Animation. -->
            <div class="columns is-centered">
              <div class="column is-full-width">
                <h2 class="title is-3">Experiment</h2>

                <!-- Interpolating. -->
                <h3 class="title is-4">Diverse Language Instructions</h3>
                <div class="content has-text-justified">
                  <p>
                  We evaluate our trained policy on target object navigation, which tasks the robot with navigating toward a visible target object from the current robot pose, in the various natural environments, which is not seen in the training datasets.
                  </p>
                </div>
          </div>
      </section>

    <!-- Results Carousel -->
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-bww1">
                        <video poster="" id="bww1" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/whiteboard.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-tello">
                        <video poster="" id="tello" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/stairs.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-outside">
                        <video poster="" id="go1-outside" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/person_sitting.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-soda3-left">
                        <video poster="" id="soda3-left" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/orange_vertical.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-rfs">
                        <video poster="" id="rfs" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/orange_bins.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-inside-1">
                        <video poster="" id="go1-inside-1" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/glass_showcase.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-viewpoints">
                        <video poster="" id="viewpoints" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/fridge.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-inside-2">
                        <video poster="" id="go1-inside-2" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/bust.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-soda3-right">
                        <video poster="" id="soda3-right" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/brick_stairs.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-soda3-right">
                        <video poster="" id="soda3-right" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/coffee_machine.mp4" type="video/mp4">
                        </video>
                    </div>                    
                </div>
            </div>            
        </div>
    </section>

      <section class="section">
        <div class="container is-max-desktop">

          <div class="columns is-centered">


            <!-- Animation. -->
            <div class="columns is-centered">
              <div class="column is-full-width">
                <!-- Interpolating. -->
                <h3 class="title is-4">Robustness for Noisy Instructions</h3>
                <div class="content has-text-justified">
                  <p>
                  Our method can show the robustness for the noisy instructions, which partially includes wrong words. 
                  </p>
                </div>
            <center>    
            <video autoplay muted loop playsinline width="80%">
              <source src="static/videos/robust_perform.mp4" type="video/mp4">
            </video>             
            </center>  
          </div>
      </section>

      <section class="section">
        <div class="container is-max-desktop">

          <div class="columns is-centered">


            <!-- Animation. -->
            <div class="columns is-centered">
              <div class="column is-full-width">
                <br />
                <!--/ Interpolating. -->

                <!-- Re-rendering. -->
                <h3 class="title is-4">Following Pedestrian</h3>
                <div class="content has-text-justified">
                  <p>
                  Due to the fast calculation of our relatively small-size policy on the robot edge controller, our method allows us to follow the dynamic target objects, such as pedestrians. 
                  </p>
                </div>
          </div>
      </section>

    <!-- Results Carousel -->
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-bww1">
                        <video poster="" id="bww1" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/dynamic_1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-tello">
                        <video poster="" id="tello" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/dynamic_2.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-outside">
                        <video poster="" id="go1-outside" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/dynamic_3.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-outside">
                        <video poster="" id="go1-outside" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/dynamic_4.mp4" type="video/mp4">
                        </video>
                    </div>                    
                </div>
            </div>
        </div>
    </section>
      
      <section class="section">
        <div class="container is-max-desktop">

          <div class="columns is-centered">


            <!-- Animation. -->
            <div class="columns is-centered">
              <div class="column is-full-width">
                <br />
                <!--/ Interpolating. -->

                <!-- Re-rendering. -->
                <h3 class="title is-4">Cross Embodiment Navigation</h3>
                <div class="content has-text-justified">
                  <p>
                  Given that our proposed method leverages in-the-wild videos recorded by a variety of cameras at different poses for training, it is inherently capable of generalizing to different embodiments. 
                  To rigorously evaluate our policies' cross-embodiment capabilities, we test our policy on the three different robot setups, 1) quadruped robot, GO1 with PCB-mounted fisheye camera, 2) same mobile robot with different cameras such as Intel Realsense D435i, PCB-mounted fisheye camera, and Ricoh Theta S.
                  </p>
                </div>
          </div>
      </section>

    <!-- Results Carousel -->
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-bww1">
                        <video poster="" id="go1_1" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/go1_1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-tello">
                        <video poster="" id="d435_1" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/d435_1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-outside">
                        <video poster="" id="height_1" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/height_1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-outside">
                        <video poster="" id="ricoh_1" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/ricoh_1.mp4" type="video/mp4">
                        </video>
                    </div>                    
                    <div class="item item-soda3-left">
                        <video poster="" id="d435_2" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/d435_2.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-rfs">
                        <video poster="" id="fisheye_1" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/fisheye_1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-outside">
                        <video poster="" id="ricoh_2" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/ricoh_2.mp4" type="video/mp4">
                        </video>
                    </div>                       
                    <div class="item item-go1-inside-1">
                        <video poster="" id="go1_2" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/go1_2.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-viewpoints">
                        <video poster="" id="d435_3" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/d435_3.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-inside-2">
                        <video poster="" id="height_2" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/height_2.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-soda3-right">
                        <video poster="" id="fisheye_2" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/fisheye_2.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-outside">
                        <video poster="" id="ricoh_3" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/ricoh_3.mp4" type="video/mp4">
                        </video>
                    </div>                       
                    <div class="item item-go1-inside-1">
                        <video poster="" id="go1_3" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/go1_3.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-viewpoints">
                        <video poster="" id="d435_4" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/d435_4.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-inside-2">
                        <video poster="" id="height_3" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/height_3.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-outside">
                        <video poster="" id="ricoh_4" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/ricoh_4.mp4" type="video/mp4">
                        </video>
                    </div>                       
                    <div class="item item-soda3-right">
                        <video poster="" id="d435_5" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/d435_5.mp4" type="video/mp4">
                        </video>
                    </div>                    
                </div>
            </div>
        </div>
    </section>

      <section class="section">
        <div class="container is-max-desktop">

          <div class="columns is-centered">


            <!-- Animation. -->
            <div class="columns is-centered">
              <div class="column is-full-width">
                <!-- Interpolating. -->
                <h3 class="title is-4">Collision Avoidance</h3>
                <div class="content has-text-justified">
                  <p>
                  By distilling the navigation foundation model, NoMaD, our policy enables the robots to avoid the collision for the obstacles between the target object and the initial robot location.
                  </p>
                </div>
            <center>    
            <video autoplay muted loop playsinline width="100%">
              <source src="static/videos/collision.mp4" type="video/mp4">
            </video>             
            </center>  
          </div>
      </section>

      <section class="section">
        <div class="container is-max-desktop">

          <div class="columns is-centered">


            <!-- Animation. -->
            <div class="columns is-centered">
              <div class="column is-full-width">
                <br />
                <!--/ Interpolating. -->

                <!-- Re-rendering. -->
                <h3 class="title is-4">Multiple Objects</h3>
                <div class="content has-text-justified">
                  <p>
                  Even when there are objects in the same type as the target object, our method distinguishes them from the prompts and allows navigation toward the correct target objects, 
                  </p>
                </div>
          </div>
      </section>

    <!-- Results Carousel -->
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-bww1">
                        <video poster="" id="bww1" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/multi_1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-tello">
                        <video poster="" id="tello" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/multi_2.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-outside">
                        <video poster="" id="go1-outside" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/multi_3.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-outside">
                        <video poster="" id="go1-outside" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/multi_4.mp4" type="video/mp4">
                        </video>
                    </div>                    
                </div>
            </div>
        </div>
    </section>

      <section class="section">
        <div class="container is-max-desktop">

          <div class="columns is-centered">


            <!-- Animation. -->
            <div class="columns is-centered">
              <div class="column is-full-width">
                <br />
                <!--/ Interpolating. -->

                <!-- Re-rendering. -->
                <h3 class="title is-4">Long-distance Navigation with Topological Memory</h3>
                <div class="content has-text-justified">
                  <p>
                  We can use the LeLaN to move toward the far target object, which is not seen in the current observation. 
                  We leverage the topological memory (stack of pre-collected images) to look for the target object and indentify the target node. 
                  At first stage (graph navigation phase), we navigate the robot to the target node location by vision-based navigation with the topological memory.
                  When arrving at the target node, we switch the policy to the LeLan and navigate toward the target object location (final approach phase). 
                  In our implementation, we use the ViNT in the first graph navigation phase.
                  </p>
                </div>
          </div>
      </section>

    <!-- Results Carousel -->
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-bww1">
                        <video poster="" id="bww1" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/topo_blue_trash_box.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-tello">
                        <video poster="" id="tello" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/topo_silver_dishwasher.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-outside">
                        <video poster="" id="go1-outside" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/topo_orange_flower.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-outside">
                        <video poster="" id="go1-outside" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/topo_green_box.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-outside">
                        <video poster="" id="go1-outside" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/topo_green_couch.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-outside">
                        <video poster="" id="go1-outside" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/topo_black_cart.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-go1-outside">
                        <video poster="" id="go1-outside" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/topo_black_chair.mp4" type="video/mp4">
                        </video>
                    </div>                                                                                
                </div>
            </div>
        </div>
    </section>

    <section class="section" id="BibTeX">  
      <div class="container is-max-desktop">    
        <h2 class="title">BibTeX</h2>
        <pre><code> @inproceedings{hirose24lelan,
        title={LeLaN: Learning A Language-conditioned Navigation Policy from In-the-Wild Video},
        author={Noriaki Hirose and Catherine Glossop and Ajay Sridhar and Dhruv Shah and Oier Mees and Sergey Levine},
        booktitle={Conference on Robot Learning},
        year={2024}
        } </code></pre>            
      </div>
    </section>

    <br>
    <center class="is-size-10">
      The website (<a href="https://github.com/learning-language-navigation/learning-language-navigation.github.io.git">source code</a>) design was adapted from <a href="https://nerfies.github.io" class="external-link"><span
                class="dnerf">Nerfies</span></a>.
    </center>
    <br>
</body>

</html>
